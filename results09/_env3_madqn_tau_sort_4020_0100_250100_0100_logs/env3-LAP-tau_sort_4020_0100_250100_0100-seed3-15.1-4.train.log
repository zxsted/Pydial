RESULTS:: 11:14:34: root                                   pydial.py <train_command>791 :  List of domains: Laptops11
RESULTS:: 11:14:34: root                                      pydial.py <trainBatch>409 :  *** Training Iteration env3-LAP-tau_sort_4020_0100_250100_0100-seed3-15.0->env3-LAP-tau_sort_4020_0100_250100_0100-seed3-15.1: iter=0, error-rate=15, num-dialogs=1000 ***
RESULTS:: 11:47:07: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 11:47:07: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 1000
RESULTS:: 11:47:07: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 3.36 +- 0.71
RESULTS:: 11:47:07: root                               EvaluationManager.py <_prstr>179 :  Average success = 66.60 +- 2.93
RESULTS:: 11:47:07: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 9.96 +- 0.29
RESULTS:: 11:47:07: root                                   pydial.py <setEvalConfig>470 :  *** Evaluating env3-LAP-tau_sort_4020_0100_250100_0100-seed3-15.1: error-rate=15 num-dialogs=500 ***
RESULTS:: 12:00:19: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 12:00:19: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 500
RESULTS:: 12:00:19: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 8.03 +- 0.76
RESULTS:: 12:00:19: root                               EvaluationManager.py <_prstr>179 :  Average success = 81.20 +- 3.43
RESULTS:: 12:00:19: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 8.21 +- 0.29
RESULTS:: 12:00:19: root                                   pydial.py <train_command>791 :  List of domains: Laptops11
RESULTS:: 12:00:19: root                                      pydial.py <trainBatch>409 :  *** Training Iteration env3-LAP-tau_sort_4020_0100_250100_0100-seed3-15.1->env3-LAP-tau_sort_4020_0100_250100_0100-seed3-15.2: iter=1, error-rate=15, num-dialogs=1000 ***
RESULTS:: 12:35:10: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 12:35:10: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 1000
RESULTS:: 12:35:10: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 6.78 +- 0.62
RESULTS:: 12:35:10: root                               EvaluationManager.py <_prstr>179 :  Average success = 86.90 +- 2.09
RESULTS:: 12:35:10: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 10.60 +- 0.34
RESULTS:: 12:35:10: root                                   pydial.py <setEvalConfig>470 :  *** Evaluating env3-LAP-tau_sort_4020_0100_250100_0100-seed3-15.2: error-rate=15 num-dialogs=500 ***
RESULTS:: 12:48:18: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 12:48:18: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 500
RESULTS:: 12:48:18: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 6.64 +- 0.86
RESULTS:: 12:48:18: root                               EvaluationManager.py <_prstr>179 :  Average success = 74.80 +- 3.81
RESULTS:: 12:48:18: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 8.32 +- 0.32
RESULTS:: 12:48:18: root                                   pydial.py <train_command>791 :  List of domains: Laptops11
RESULTS:: 12:48:18: root                                      pydial.py <trainBatch>409 :  *** Training Iteration env3-LAP-tau_sort_4020_0100_250100_0100-seed3-15.2->env3-LAP-tau_sort_4020_0100_250100_0100-seed3-15.3: iter=2, error-rate=15, num-dialogs=1000 ***
RESULTS:: 13:24:17: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 13:24:17: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 1000
RESULTS:: 13:24:17: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 5.83 +- 0.66
RESULTS:: 13:24:17: root                               EvaluationManager.py <_prstr>179 :  Average success = 82.90 +- 2.34
RESULTS:: 13:24:17: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 10.75 +- 0.33
RESULTS:: 13:24:17: root                                   pydial.py <setEvalConfig>470 :  *** Evaluating env3-LAP-tau_sort_4020_0100_250100_0100-seed3-15.3: error-rate=15 num-dialogs=500 ***
RESULTS:: 13:39:11: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 13:39:11: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 500
RESULTS:: 13:39:11: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 6.68 +- 0.85
RESULTS:: 13:39:11: root                               EvaluationManager.py <_prstr>179 :  Average success = 78.00 +- 3.64
RESULTS:: 13:39:11: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 8.92 +- 0.37
RESULTS:: 13:39:11: root                                   pydial.py <train_command>791 :  List of domains: Laptops11
RESULTS:: 13:39:11: root                                      pydial.py <trainBatch>409 :  *** Training Iteration env3-LAP-tau_sort_4020_0100_250100_0100-seed3-15.3->env3-LAP-tau_sort_4020_0100_250100_0100-seed3-15.4: iter=3, error-rate=15, num-dialogs=1000 ***
RESULTS:: 14:18:47: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 14:18:47: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 1000
RESULTS:: 14:18:47: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 5.31 +- 0.68
RESULTS:: 14:18:47: root                               EvaluationManager.py <_prstr>179 :  Average success = 82.60 +- 2.35
RESULTS:: 14:18:47: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 11.21 +- 0.35
RESULTS:: 14:18:47: root                                   pydial.py <setEvalConfig>470 :  *** Evaluating env3-LAP-tau_sort_4020_0100_250100_0100-seed3-15.4: error-rate=15 num-dialogs=500 ***
RESULTS:: 14:35:09: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 14:35:09: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 500
RESULTS:: 14:35:09: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 7.83 +- 0.84
RESULTS:: 14:35:09: root                               EvaluationManager.py <_prstr>179 :  Average success = 84.00 +- 3.22
RESULTS:: 14:35:09: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 8.97 +- 0.35
RESULTS:: 14:35:09: root                                   pydial.py <train_command>807 :  *** Training complete. log: env3-LAP-tau_sort_4020_0100_250100_0100-seed3-15.1-4.train.log - final policy is env3-LAP-tau_sort_4020_0100_250100_0100-15-04
