RESULTS:: 16:23:09: root                                   pydial.py <train_command>791 :  List of domains: Laptops11
RESULTS:: 16:23:09: root                                      pydial.py <trainBatch>409 :  *** Training Iteration env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.0->env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.1: iter=0, error-rate=15, num-dialogs=1000 ***
RESULTS:: 16:58:00: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 16:58:00: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 1000
RESULTS:: 16:58:00: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 2.75 +- 0.73
RESULTS:: 16:58:00: root                               EvaluationManager.py <_prstr>179 :  Average success = 66.90 +- 2.92
RESULTS:: 16:58:00: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 10.63 +- 0.30
RESULTS:: 16:58:00: root                                   pydial.py <setEvalConfig>470 :  *** Evaluating env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.1: error-rate=15 num-dialogs=500 ***
RESULTS:: 17:10:56: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 17:10:56: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 500
RESULTS:: 17:10:56: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 4.31 +- 0.93
RESULTS:: 17:10:56: root                               EvaluationManager.py <_prstr>179 :  Average success = 62.20 +- 4.26
RESULTS:: 17:10:56: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 8.13 +- 0.29
RESULTS:: 17:10:56: root                                   pydial.py <train_command>791 :  List of domains: Laptops11
RESULTS:: 17:10:56: root                                      pydial.py <trainBatch>409 :  *** Training Iteration env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.1->env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.2: iter=1, error-rate=15, num-dialogs=1000 ***
RESULTS:: 17:47:32: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 17:47:32: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 1000
RESULTS:: 17:47:32: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 4.99 +- 0.70
RESULTS:: 17:47:32: root                               EvaluationManager.py <_prstr>179 :  Average success = 77.30 +- 2.60
RESULTS:: 17:47:32: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 10.47 +- 0.33
RESULTS:: 17:47:32: root                                   pydial.py <setEvalConfig>470 :  *** Evaluating env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.2: error-rate=15 num-dialogs=500 ***
RESULTS:: 18:01:00: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 18:01:00: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 500
RESULTS:: 18:01:00: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 4.36 +- 0.97
RESULTS:: 18:01:00: root                               EvaluationManager.py <_prstr>179 :  Average success = 64.60 +- 4.20
RESULTS:: 18:01:00: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 8.56 +- 0.28
RESULTS:: 18:01:00: root                                   pydial.py <train_command>791 :  List of domains: Laptops11
RESULTS:: 18:01:00: root                                      pydial.py <trainBatch>409 :  *** Training Iteration env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.2->env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.3: iter=2, error-rate=15, num-dialogs=1000 ***
RESULTS:: 18:34:40: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 18:34:40: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 1000
RESULTS:: 18:34:40: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 6.22 +- 0.64
RESULTS:: 18:34:40: root                               EvaluationManager.py <_prstr>179 :  Average success = 83.40 +- 2.31
RESULTS:: 18:34:40: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 10.46 +- 0.32
RESULTS:: 18:34:40: root                                   pydial.py <setEvalConfig>470 :  *** Evaluating env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.3: error-rate=15 num-dialogs=500 ***
RESULTS:: 18:48:32: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 18:48:32: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 500
RESULTS:: 18:48:32: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 9.09 +- 0.70
RESULTS:: 18:48:32: root                               EvaluationManager.py <_prstr>179 :  Average success = 89.60 +- 2.68
RESULTS:: 18:48:32: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 8.83 +- 0.34
RESULTS:: 18:48:32: root                                   pydial.py <train_command>791 :  List of domains: Laptops11
RESULTS:: 18:48:32: root                                      pydial.py <trainBatch>409 :  *** Training Iteration env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.3->env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.4: iter=3, error-rate=15, num-dialogs=1000 ***
RESULTS:: 19:22:33: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 19:22:33: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 1000
RESULTS:: 19:22:33: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 6.84 +- 0.58
RESULTS:: 19:22:33: root                               EvaluationManager.py <_prstr>179 :  Average success = 86.70 +- 2.11
RESULTS:: 19:22:33: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 10.50 +- 0.31
RESULTS:: 19:22:33: root                                   pydial.py <setEvalConfig>470 :  *** Evaluating env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.4: error-rate=15 num-dialogs=500 ***
RESULTS:: 19:36:33: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 19:36:33: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 500
RESULTS:: 19:36:33: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 7.86 +- 0.78
RESULTS:: 19:36:33: root                               EvaluationManager.py <_prstr>179 :  Average success = 85.20 +- 3.12
RESULTS:: 19:36:33: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 9.18 +- 0.36
RESULTS:: 19:36:33: root                                   pydial.py <train_command>791 :  List of domains: Laptops11
RESULTS:: 19:36:33: root                                      pydial.py <trainBatch>409 :  *** Training Iteration env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.4->env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.5: iter=4, error-rate=15, num-dialogs=1000 ***
RESULTS:: 20:10:40: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 20:10:40: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 1000
RESULTS:: 20:10:40: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 6.51 +- 0.64
RESULTS:: 20:10:40: root                               EvaluationManager.py <_prstr>179 :  Average success = 85.20 +- 2.20
RESULTS:: 20:10:40: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 10.53 +- 0.33
RESULTS:: 20:10:40: root                                   pydial.py <setEvalConfig>470 :  *** Evaluating env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.5: error-rate=15 num-dialogs=500 ***
RESULTS:: 20:23:40: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 20:23:40: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 500
RESULTS:: 20:23:40: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 8.63 +- 0.72
RESULTS:: 20:23:40: root                               EvaluationManager.py <_prstr>179 :  Average success = 85.20 +- 3.12
RESULTS:: 20:23:40: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 8.41 +- 0.30
RESULTS:: 20:23:40: root                                   pydial.py <train_command>791 :  List of domains: Laptops11
RESULTS:: 20:23:40: root                                      pydial.py <trainBatch>409 :  *** Training Iteration env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.5->env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.6: iter=5, error-rate=15, num-dialogs=1000 ***
RESULTS:: 20:56:45: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 20:56:45: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 1000
RESULTS:: 20:56:45: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 6.72 +- 0.61
RESULTS:: 20:56:45: root                               EvaluationManager.py <_prstr>179 :  Average success = 85.80 +- 2.17
RESULTS:: 20:56:45: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 10.44 +- 0.31
RESULTS:: 20:56:45: root                                   pydial.py <setEvalConfig>470 :  *** Evaluating env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.6: error-rate=15 num-dialogs=500 ***
RESULTS:: 21:10:59: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 21:10:59: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 500
RESULTS:: 21:10:59: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 8.43 +- 0.77
RESULTS:: 21:10:59: root                               EvaluationManager.py <_prstr>179 :  Average success = 88.00 +- 2.86
RESULTS:: 21:10:59: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 9.17 +- 0.36
RESULTS:: 21:10:59: root                                   pydial.py <train_command>791 :  List of domains: Laptops11
RESULTS:: 21:10:59: root                                      pydial.py <trainBatch>409 :  *** Training Iteration env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.6->env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.7: iter=6, error-rate=15, num-dialogs=1000 ***
RESULTS:: 21:44:43: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 21:44:43: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 1000
RESULTS:: 21:44:43: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 7.00 +- 0.60
RESULTS:: 21:44:43: root                               EvaluationManager.py <_prstr>179 :  Average success = 87.30 +- 2.07
RESULTS:: 21:44:43: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 10.46 +- 0.33
RESULTS:: 21:44:43: root                                   pydial.py <setEvalConfig>470 :  *** Evaluating env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.7: error-rate=15 num-dialogs=500 ***
RESULTS:: 21:59:00: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 21:59:00: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 500
RESULTS:: 21:59:00: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 9.07 +- 0.74
RESULTS:: 21:59:00: root                               EvaluationManager.py <_prstr>179 :  Average success = 89.60 +- 2.68
RESULTS:: 21:59:00: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 8.85 +- 0.38
RESULTS:: 21:59:00: root                                   pydial.py <train_command>791 :  List of domains: Laptops11
RESULTS:: 21:59:00: root                                      pydial.py <trainBatch>409 :  *** Training Iteration env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.7->env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.8: iter=7, error-rate=15, num-dialogs=1000 ***
RESULTS:: 22:33:31: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 22:33:31: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 1000
RESULTS:: 22:33:31: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 6.70 +- 0.63
RESULTS:: 22:33:31: root                               EvaluationManager.py <_prstr>179 :  Average success = 87.50 +- 2.05
RESULTS:: 22:33:31: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 10.80 +- 0.35
RESULTS:: 22:33:31: root                                   pydial.py <setEvalConfig>470 :  *** Evaluating env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.8: error-rate=15 num-dialogs=500 ***
RESULTS:: 22:46:32: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 22:46:32: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 500
RESULTS:: 22:46:32: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 4.09 +- 0.93
RESULTS:: 22:46:32: root                               EvaluationManager.py <_prstr>179 :  Average success = 61.40 +- 4.28
RESULTS:: 22:46:32: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 8.19 +- 0.29
RESULTS:: 22:46:32: root                                   pydial.py <train_command>791 :  List of domains: Laptops11
RESULTS:: 22:46:32: root                                      pydial.py <trainBatch>409 :  *** Training Iteration env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.8->env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.9: iter=8, error-rate=15, num-dialogs=1000 ***
RESULTS:: 23:20:51: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 23:20:51: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 1000
RESULTS:: 23:20:51: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 6.54 +- 0.66
RESULTS:: 23:20:51: root                               EvaluationManager.py <_prstr>179 :  Average success = 86.40 +- 2.13
RESULTS:: 23:20:51: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 10.73 +- 0.35
RESULTS:: 23:20:51: root                                   pydial.py <setEvalConfig>470 :  *** Evaluating env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.9: error-rate=15 num-dialogs=500 ***
RESULTS:: 23:35:00: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 23:35:00: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 500
RESULTS:: 23:35:00: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 7.59 +- 0.81
RESULTS:: 23:35:00: root                               EvaluationManager.py <_prstr>179 :  Average success = 83.40 +- 3.27
RESULTS:: 23:35:00: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 9.09 +- 0.34
RESULTS:: 23:35:00: root                                   pydial.py <train_command>791 :  List of domains: Laptops11
RESULTS:: 23:35:00: root                                      pydial.py <trainBatch>409 :  *** Training Iteration env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.9->env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.10: iter=9, error-rate=15, num-dialogs=1000 ***
RESULTS:: 00:08:13: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 00:08:13: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 1000
RESULTS:: 00:08:13: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 6.64 +- 0.65
RESULTS:: 00:08:13: root                               EvaluationManager.py <_prstr>179 :  Average success = 85.40 +- 2.19
RESULTS:: 00:08:13: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 10.44 +- 0.33
RESULTS:: 00:08:13: root                                   pydial.py <setEvalConfig>470 :  *** Evaluating env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.10: error-rate=15 num-dialogs=500 ***
RESULTS:: 00:21:43: root                               EvaluationManager.py <_prstr>179 :  Results for domain: Laptops11 --evaluated by: objective success evaluator
RESULTS:: 00:21:43: root                               EvaluationManager.py <_prstr>179 :  # of dialogues  = 500
RESULTS:: 00:21:43: root                               EvaluationManager.py <_prstr>179 :  Average reward  = 8.95 +- 0.75
RESULTS:: 00:21:43: root                               EvaluationManager.py <_prstr>179 :  Average success = 88.00 +- 2.86
RESULTS:: 00:21:43: root                               EvaluationManager.py <_prstr>179 :  Average turns   = 8.65 +- 0.36
RESULTS:: 00:21:43: root                                   pydial.py <train_command>807 :  *** Training complete. log: env3-LAP-tau_sort_4020_0100_250100_0100-seed7-15.1-10.train.log - final policy is env3-LAP-tau_sort_4020_0100_250100_0100-15-10
